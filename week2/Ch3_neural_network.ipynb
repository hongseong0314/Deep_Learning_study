{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch3_neural_network.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1mdhVyPX10RgZPHTuUQgLnOr2LpP6EopJ","authorship_tag":"ABX9TyPF12jM37iXmsAwiBVuNz/J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"24AdCfCsThis"},"source":["# What is a Neural Network and How does it work?"]},{"cell_type":"markdown","metadata":{"id":"qWSwiDc-Tmvr"},"source":["<h3>What is a Neural Network?</h3>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","A neural network constists of 3 main layers: Input layer, Hidden layer, and the Output layer. In order to get how it works, we need to go through a recap about how the Perceptron works.\n","</p>\n","\n","<h3>How does the Perceptron work?</h3>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Perceptron is an algorithm to \"learn\" the binary classifier, which is composed of a \"linear combination\" of an input vector $X$ and a weight vector $W$, and usually a bias vector $b$ is added.<br>\n","A weight vector controls the impact of the input vector(especially elements of it) and a bias vector controls how easily a neuron is activated.<br>\n","To be noted, a bias vector can be understood as a result of the linear combination between an input vector and a weight vector, where a scalar '1' is in the input vector and another scalar 'b' is in the weight vector.<br>\n","The perceptron requires the output value to be discrete since it is used for (binary) classification, while it cannot be guaranteed that the result of the linear combination is always discrete.<br>\n","Thus, we need another function to make the linear combination value discrete, namely an 'Activation function'.\n","</p>\n","\n","<h3>What is an 'Activation function'?</h3>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","An activation function is a function which transforms a given value into an output value. The given value here is a 'transformed' input value with its weight and bias.<br>\n","</p>\n","<p>\n","There are various kinds of an activation function. The perceptron uses a function called 'Threshold function' as its activation function, which is generally called 'Step function'.<br>\n","A step function is a function that restricts the output value in the possible range, according to a criterion called 'threshold', where the function returns a specific value if the given input is larger than the threshold, and returns another specific value otherwise. Here are some well-known examples of a step function.\n","</p>\n","\n","<h4>1. Sigmoid Function</h4>\n","<p style=\"font-size:13pt;line-height:19pt\">Sigmoid function restricts the output in the open interval $(0, 1)$. The function looks like $h(x)=\\frac{1}{1+\\exp (-x)}$. As $x$ gets close to $\\infty$, the $\\exp (-x)$ part goes to $0$, making the entire function converge to $1$. As $x$ goes to $-\\infty$, however, the $\\exp(-x)$ part diverges to $\\infty$, the entire function converges to $0$. Furthermore, if $x=0$, since the $exp(0)=1$, thus making the function equals to $\\frac{1}{2}$.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">Let's make a step function of a simple form.\n","</p>"]},{"cell_type":"code","metadata":{"id":"ZLywRLo_iEz5","executionInfo":{"status":"ok","timestamp":1633064844018,"user_tz":-540,"elapsed":537,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tO-XjjXTmYe","executionInfo":{"status":"ok","timestamp":1633064844494,"user_tz":-540,"elapsed":24,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["# Code for implementation of a step function\n","# This works only for a scalar-type input\n","def step_function_scalar(x):\n","  if x > 0:\n","    return 1\n","  else:\n","    return 0"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmKst-ZUhi7W","executionInfo":{"status":"ok","timestamp":1633064844495,"user_tz":-540,"elapsed":24,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["# A step function works for both scalar-type and vector-type\n","def step_function_vector(x):\n","  y = x > 0 # returns an array containing values of boolean type, indicating whether each element is larger than the threshold or not\n","  print(\"True Value is: {}\".format(y))\n","\n","  return y.astype(np.int) # transforms a type of value into as an integer"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKUYCYVkSWkx","executionInfo":{"status":"ok","timestamp":1633064844495,"user_tz":-540,"elapsed":24,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"c64aa3b2-35bd-46c7-9c8c-d5c0709fc82a"},"source":["A = np.array([3, 3], dtype=np.float64)\n","\n","try:\n","  print(step_function_scalar(A[0])) # 3\n","  print(step_function_scalar(A)) # vector\n","except Exception as e:\n","  print(e)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlC3e0SWSkql","executionInfo":{"status":"ok","timestamp":1633064844495,"user_tz":-540,"elapsed":20,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"fe7985a8-e734-495c-82e5-5bb3ea00c6fe"},"source":["try:\n","  print(step_function_vector(A[0])) # 3\n","  print(step_function_vector(A)) # vector\n","except Exception as e:\n","  print(e)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["True Value is: True\n","1\n","True Value is: [ True  True]\n","[1 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"KKmfFMIhkK3D"},"source":["## Plotting a step function"]},{"cell_type":"code","metadata":{"id":"lLoTjnpQjJSo","executionInfo":{"status":"ok","timestamp":1633064844496,"user_tz":-540,"elapsed":18,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9Xxuk4jkUDc","executionInfo":{"status":"ok","timestamp":1633064844496,"user_tz":-540,"elapsed":18,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def step_function(x):\n","  return np.array(x > 0, dtype=np.int)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSyprWf7kiEE","executionInfo":{"status":"ok","timestamp":1633064844496,"user_tz":-540,"elapsed":18,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"3c9091a6-ae7e-43ac-eeae-a87888294325"},"source":["B = np.array([[0, 1], [3, -2]], dtype=np.float64)\n","B"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.,  1.],\n","       [ 3., -2.]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPWe1pzlkrXE","executionInfo":{"status":"ok","timestamp":1633064844497,"user_tz":-540,"elapsed":14,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"b70a49b2-5c74-4621-cc6e-f2460492a81c"},"source":["step_function(B)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1],\n","       [1, 0]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"9kxAjnygksgo","executionInfo":{"status":"ok","timestamp":1633064844497,"user_tz":-540,"elapsed":12,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["# This anonymous function works exactly the same as the function defined above\n","stpf = lambda x: np.array(x > 0, dtype=np.float64)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGqz42_wk276","executionInfo":{"status":"ok","timestamp":1633064844498,"user_tz":-540,"elapsed":12,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"b9d07b48-6708-447d-8cde-55ba0d85979c"},"source":["stpf(B)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1.],\n","       [1., 0.]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"0c5Sl5sxk3-b","executionInfo":{"status":"ok","timestamp":1633064844498,"user_tz":-540,"elapsed":10,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["X = np.arange(-5.0, 5.0, 0.1) # a method genrating numbers from start to end, especially incrementing from the start by the amount of the given interval\n","y = stpf(X)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w67PO-CDmGDO","executionInfo":{"status":"ok","timestamp":1633064844498,"user_tz":-540,"elapsed":10,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"0eb7484e-edab-4832-c7b4-1ade1d7220f9"},"source":["print(X)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[-5.00000000e+00 -4.90000000e+00 -4.80000000e+00 -4.70000000e+00\n"," -4.60000000e+00 -4.50000000e+00 -4.40000000e+00 -4.30000000e+00\n"," -4.20000000e+00 -4.10000000e+00 -4.00000000e+00 -3.90000000e+00\n"," -3.80000000e+00 -3.70000000e+00 -3.60000000e+00 -3.50000000e+00\n"," -3.40000000e+00 -3.30000000e+00 -3.20000000e+00 -3.10000000e+00\n"," -3.00000000e+00 -2.90000000e+00 -2.80000000e+00 -2.70000000e+00\n"," -2.60000000e+00 -2.50000000e+00 -2.40000000e+00 -2.30000000e+00\n"," -2.20000000e+00 -2.10000000e+00 -2.00000000e+00 -1.90000000e+00\n"," -1.80000000e+00 -1.70000000e+00 -1.60000000e+00 -1.50000000e+00\n"," -1.40000000e+00 -1.30000000e+00 -1.20000000e+00 -1.10000000e+00\n"," -1.00000000e+00 -9.00000000e-01 -8.00000000e-01 -7.00000000e-01\n"," -6.00000000e-01 -5.00000000e-01 -4.00000000e-01 -3.00000000e-01\n"," -2.00000000e-01 -1.00000000e-01 -1.77635684e-14  1.00000000e-01\n","  2.00000000e-01  3.00000000e-01  4.00000000e-01  5.00000000e-01\n","  6.00000000e-01  7.00000000e-01  8.00000000e-01  9.00000000e-01\n","  1.00000000e+00  1.10000000e+00  1.20000000e+00  1.30000000e+00\n","  1.40000000e+00  1.50000000e+00  1.60000000e+00  1.70000000e+00\n","  1.80000000e+00  1.90000000e+00  2.00000000e+00  2.10000000e+00\n","  2.20000000e+00  2.30000000e+00  2.40000000e+00  2.50000000e+00\n","  2.60000000e+00  2.70000000e+00  2.80000000e+00  2.90000000e+00\n","  3.00000000e+00  3.10000000e+00  3.20000000e+00  3.30000000e+00\n","  3.40000000e+00  3.50000000e+00  3.60000000e+00  3.70000000e+00\n","  3.80000000e+00  3.90000000e+00  4.00000000e+00  4.10000000e+00\n","  4.20000000e+00  4.30000000e+00  4.40000000e+00  4.50000000e+00\n","  4.60000000e+00  4.70000000e+00  4.80000000e+00  4.90000000e+00]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"vbhX7tfGmDyI","executionInfo":{"status":"ok","timestamp":1633064845151,"user_tz":-540,"elapsed":660,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"e06f9b6f-1a6b-4abd-bf5b-e6d0c1cf578f"},"source":["plt.plot(X, y)\n","plt.ylim(-0.1, 1.1)\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"g3RLyW_wGzn0"},"source":["## Implementing and Plotting the Sigmoid Function"]},{"cell_type":"code","metadata":{"id":"C3sw3ei1mc35","executionInfo":{"status":"ok","timestamp":1633064845151,"user_tz":-540,"elapsed":81,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def sigmoid(x):\n","  return 1 / (1+np.exp(-x))\n","\n","# or sigmoid = lambda x: 1 / (1+np.exp(-x))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"GVpVm455HClE","executionInfo":{"status":"ok","timestamp":1633064845151,"user_tz":-540,"elapsed":80,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"7511d53f-07ef-448a-c8fd-3176cd05efbd"},"source":["# The function defined above can also treat the vector\n","X = np.array([[0.002, -0.5], [4, 6], [-3, 10], [-120000, 10000000]], dtype=np.float64)\n","\n","sigmoid(X)\n","\n","\"\"\"\n","As we can see, if x goes closer to the positive infinity, then the sigmoid function returns 1,\n","while it returns 0 as x goes closer to the negative infinity.\n","Also, if x is close to zero, the sigmoid function returns a value close to 0.5\n","\"\"\""],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n","  \n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nAs we can see, if x goes closer to the positive infinity, then the sigmoid function returns 1,\\nwhile it returns 0 as x goes closer to the negative infinity.\\nAlso, if x is close to zero, the sigmoid function returns a value close to 0.5\\n'"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"C6mEW_stHeaD","executionInfo":{"status":"ok","timestamp":1633064845152,"user_tz":-540,"elapsed":74,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"592c6d2f-329b-40da-a642-a91082a55ade"},"source":["# plotting sigmoid function\n","\n","X = np.arange(-5.0, 5.0, 0.1)\n","y = sigmoid(X)\n","\n","plt.plot(X, y)\n","plt.ylim(-0.1, 1.1)\n","plt.show()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAe+klEQVR4nO3dd3yV9d3/8deH7JAFJIwkTNlTJAJqq1bR4gLrBB9qndBWrVrH7brtXe2vVds6+tNbRa0DRYqILa0ojp/rdiBhhD3CTFhJCNnz5Hx/fyRyRwQS4CRXcs77+XicBznXuZLzvkjyfnzzvZY55xARkfavg9cBREQkMFToIiJBQoUuIhIkVOgiIkFChS4iEiTCvXrj5ORk16dPH6/eXkSkXVqyZEmBcy7lYK95Vuh9+vQhMzPTq7cXEWmXzGzboV7TlIuISJBQoYuIBAkVuohIkFChi4gECRW6iEiQUKGLiAQJFbqISJBQoYuIBAkVuohIkFChi4gECRW6iEiQUKGLiAQJFbqISJBostDN7G9mlmdmqw7xupnZX80s28xWmNkJgY8pIiJNac4I/RVg4mFePwcY0PCYBjx77LFERORINVnozrnPgcLDrDIZeM3V+wZIMrMegQooIiLNE4g59DQgp9Hz3IZlP2Bm08ws08wy8/PzA/DWIiLynVa9Y5FzbgYwAyAjI8O15nuLiARCjc9PcWUtxZU1FFfWUlLpo6SqlpLKWkqqfJRW+SirrqWsykdZdR3l1T4qanyU19RRUe2joraO+84dwmUZPQOeLRCFvgNonCy9YZmISJvnnKO4spa80mrySqrJK62ioKyagrIaCsqqKSyv2f8oqqilrNp32K8XEWbER0fQMSqMjpHhxEWFkxQbSVqnMGIjw4mNDKNvcscW2ZZAFPp84GYzmw2MA4qdc7sC8HVFRI5ZbZ2fnUWVbC+sIHdfJTv2VbKjqJJdxZXsLq5iV3EV1T7/Dz4vMrwDyR0j6RIXReeOkRyXEkdSbASdYiNJio0gMeZ/HwkxESRERxAfHU50RJgHW1mvyUI3szeB04FkM8sFfgtEADjnngMWAOcC2UAFcG1LhRURORjnHLuKq8jOK2NTfhlbCsr3P3YWVeJvNMEb1sHonhBNj8RoRqQncfawaLrGR9Etof7flPgokuOjiI8Kx8y826ij0GShO+emNvG6A24KWCIRkcMoq/axdlcJa3aWsG53Cet2l7JhdynlNXX714mPDqdvckdO6NWJi0an0bNz7P5Ht/gowsOC85zKVt0pKiJyJGp8flbvLCYrp4is3GKycovYUlCOaxhxJ8VGMKhbPJeMSad/t3j6p8TRv2scyXGR7W50HQgqdBFpM8qrfWRu28eizXvJ3LqPrNyi/fPbXeOjGNUziQuPT2NYagLDUhPplhAVksV9KCp0EfFMnd+xPKeIzzfk8z/ZBWTlFOHzO8I7GMPSErlqfG/G9O7E6F6d6J4Y7XXcNk+FLiKtqriylk/X5/HR2jw+35BPcWUtHQxGpCdx46n9OKlfFzL6dCI2UvV0pPQ/JiItrrC8hoWrd7Ng5S6+3rQXn9+RHBfJ2UO7cdqgFH7UP5mk2EivY7Z7KnQRaREVNT4Wrt7NO8t28mV2AXV+R58usdzw436cNbQbo3sm0aGD5r8DSYUuIgHjnGPJtn28+W0O763aRUVNHemdYph+aj/OG9mDoT0StBOzBanQReSYlVTVMjczlze/3c7GvDI6RoZxwchULh6TTkbvThqJtxIVuogctS0F5bzy5RbmLsmlvKaOUT2TePTiEZw/MpWOUaqX1qb/cRE5Ylk5RTz32SbeX72b8A7GBSNTueaUPoxMT/I6WkhToYtIsy3eWsiTH23gy+y9JESHc9Pp/bn65N50jdcx4m2BCl1EmrRs+z4e/3ADX2wsIDkuinvPGcwV43oRHx3hdTRpRIUuIoe0paCcx95fx3urdtO5YyT3nTuYq8b3ISbSu0vEyqGp0EXkB4oqanjyo428/s02IsM7cPuEgdzw477a0dnG6bsjIvv5/Y6/Z+bw2PvrKK6sZcrYXtw2YYDmyNsJFbqIALBqRzH3v7OSrNxixvbpzO8mD2NIjwSvY8kRUKGLhLiq2jqe/GgjL3yxmU6xkTx5+fFMPj5VZ3S2Qyp0kRCWubWQu+auYEtBOZdlpHP/uUNJjNWRK+2VCl0kBNX4/Dzx0Qae/2wTaZ1ieOOGcZzSP9nrWHKMVOgiIWbjnlJ+PXs5a3eVMOXEnjxw/lDidPRKUNB3USREOOd4a0kuD/5zFR0jw3nh6gzOGtrN61gSQCp0kRBQXu3jP/+xinnLdnBSvy48NeV4uiboUMRgo0IXCXJbCsqZPjOT7Lwybp8wkJvP6E+YLmcblFToIkHsk3V5/Hr2MsI7GK9dN44fDdCOz2CmQhcJQs45nv1sE39auJ4h3RN4/qox9Owc63UsaWEqdJEgU+Pzc987K5m7JJdJo1J59OKRuphWiFChiwSRoooaps9cwqIthdw2YQC3njlAZ3yGEBW6SJDYUVTJ1S8tIqewkicvP54LR6d5HUlaWYfmrGRmE81svZllm9k9B3m9l5l9YmbLzGyFmZ0b+Kgicigb9pRyybNfkVdazWvXj1WZh6gmC93MwoBngHOAocBUMxt6wGoPAHOcc6OBKcB/BzqoiBzckm2FXPrc19T5HXOmn8T4fl28jiQeac4IfSyQ7Zzb7JyrAWYDkw9YxwHfXWczEdgZuIgicihfZRdw5Yvf0rljJG//8mRd7jbENWcOPQ3IafQ8Fxh3wDr/BXxgZrcAHYEJB/tCZjYNmAbQq1evI80qIo18si6P6a8voW+Xjrx+wzhS4qO8jiQea9YcejNMBV5xzqUD5wIzzewHX9s5N8M5l+Gcy0hJSQnQW4uEnvdX7WbazEwGdovjzWnjVeYCNK/QdwA9Gz1Pb1jW2PXAHADn3NdANKBT0kRawAerd3PzrKUMS03kjRvG07ljpNeRpI1oTqEvBgaYWV8zi6R+p+f8A9bZDpwJYGZDqC/0/EAGFZH6aZabZi1lWFoir10/lsQY3YxC/leThe6c8wE3AwuBtdQfzbLazB4ys0kNq90B3GhmWcCbwDXOOddSoUVC0ecb8pn++hIGdY/ntevGkhCtMpfva9aJRc65BcCCA5Y92OjjNcApgY0mIt9ZvLWQaTMzOS4ljtevH6eRuRxUoHaKikgLWb2zmOteWUxqYgwzrx9LUqzmzOXgVOgibdiWgnJ+/rdviYsKZ+YN40iO09EscmgqdJE2Kq+kiqteWoTfwczrx5GWFON1JGnjVOgibVBZtY9rX1lMYXkNr1x7Iv27xnkdSdoBXW1RpI2prfPzqzeWsm53KS9encHI9CSvI0k7oRG6SBvinOO+eSv5fEM+/+fC4fxkcFevI0k7okIXaUOe/WwTby3J5ddn9GfKWF3vSI6MCl2kjXhv5S4ee389k0alcvtZA72OI+2QCl2kDViRW8Ttc5ZzQq8kHrtkpG4bJ0dFhS7isT0lVdzwaiZdOkbx/FUZREfohs5ydHSUi4iHqmrrmD5zCWXVPub96mRdBleOiQpdxCPOOf7zH6tYnlPEc1eewODuutuQHBtNuYh45NWvtu4/omXi8B5ex5EgoEIX8cCizXt5+N21TBjSjdsm6IgWCQwVukgr21NSxU2zltG7cyxPXD6KDh10RIsEhubQRVpRbZ2fm95YSnm1j1k3jiNeN6mQAFKhi7SiPyxYS+a2ffx16mgGdov3Oo4EGU25iLSSd1fs4uUvt3LtKX2YNCrV6zgShFToIq1gS0E5//H2Ckb3SuLec4Z4HUeClApdpIVV1dZx0xtLCQ8znr7iBCLD9WsnLUNz6CIt7KF/r2HNrhJe+nmG7jokLUpDBZEW9K+sncxatJ3pp/bjzCHdvI4jQU6FLtJCcgoruG/eSkb3SuLOnw7yOo6EABW6SAuorfNzy5vLwOCvU0YTEaZfNWl5mkMXaQF/+WADy3OKeOaKE+jZOdbrOBIiNGwQCbAvNubz3GebmDq2F+eN1EW3pPWo0EUCqLC8hjvmZNG/axwPnj/U6zgSYppV6GY20czWm1m2md1ziHUuM7M1ZrbazGYFNqZI2+ec4+65KyiqqOWvU0YTE6k7D0nranIO3czCgGeAs4BcYLGZzXfOrWm0zgDgXuAU59w+M+vaUoFF2qo3Fm3no7V7eOC8IQxN1c0qpPU1Z4Q+Fsh2zm12ztUAs4HJB6xzI/CMc24fgHMuL7AxRdq27Lwyfv/uGn48IJnrTunrdRwJUc0p9DQgp9Hz3IZljQ0EBprZl2b2jZlNPNgXMrNpZpZpZpn5+flHl1ikjanx+bnt78uIiQjjL5fq+ubinUDtFA0HBgCnA1OBF8ws6cCVnHMznHMZzrmMlJSUAL21iLee+ngDq3aU8MjFI+maEO11HAlhzSn0HUDPRs/TG5Y1lgvMd87VOue2ABuoL3iRoJa5tZBnP93EZRnp/HRYd6/jSIhrTqEvBgaYWV8ziwSmAPMPWOcf1I/OMbNk6qdgNgcwp0ibU1pVy+1zlpPeKZYHLxjmdRyRpgvdOecDbgYWAmuBOc651Wb2kJlNalhtIbDXzNYAnwB3Oef2tlRokbbg4X+vYce+Sp64fBRxUTrpWrzXrJ9C59wCYMEByx5s9LEDftPwEAl6H6zezZzMXG76yXGM6d3Z6zgigM4UFTliBWXV3DtvJUN7JHDrmQO9jiOyn/5OFDkCzjnum7eS0iofs248XncfkjZFP40iR+DtpTv4YM0e7vrpIAZ1j/c6jsj3qNBFmmlHUSW/m7+asX07c92PdDaotD0qdJFm8Psdd72VRZ1z/OXSUYTpbFBpg1ToIs0w85ttfLVpLw+cN1Q3rJA2S4Uu0oTN+WX88b21nD4ohaljezb9CSIeUaGLHEad33HHW1lEhYfx6MUjMdNUi7RdOmxR5DBmfL6ZZduLeGrK8XTThbekjdMIXeQQ1u0u4YkPN3DuiO5MGpXqdRyRJqnQRQ6ixufnjjlZJMSE8/Dk4ZpqkXZBUy4iB/H0J9ms3lnC81eNoUtclNdxRJpFI3SRA6zILeKZT7K5aHSarnEu7YoKXaSRqto6fjMni5S4KH6ra5xLO6MpF5FGHv9wA9l5Zbx63VgSYyO8jiNyRDRCF2mweGshL3yxmSvG9eK0gbrnrbQ/KnQRoLzax51vZZHeKYb7zh3idRyRo6IpFxHgkffWsb2wgjdvHK/byUm7pRG6hLwvNuYz85ttXH9KX8b36+J1HJGjpkKXkFZcWctdb62gf9c47vzpIK/jiBwTFbqEtN/9azX5ZdU8ftkooiPCvI4jckxU6BKy3l+1i3lLd3DTT/ozMj3J6zgix0yFLiEpr7SK+95ZxYi0RG45o7/XcUQCQoUuIcc5x71vr6Ss2scTl48iIky/BhIc9JMsIefvi3P4eF0e/zFxMP27xnsdRyRgVOgSUrbvreDhf6/hpH5duPbkPl7HEQkoFbqEDF+dn9vnLKdDB+PPl42iQwdd41yCS7MK3cwmmtl6M8s2s3sOs97FZubMLCNwEUUC47nPNrFk2z5+f+Fw0pJivI4jEnBNFrqZhQHPAOcAQ4GpZjb0IOvFA7cCiwIdUuRYrcgt4smPNnLBqFQmH5/mdRyRFtGcEfpYINs5t9k5VwPMBiYfZL2HgUeBqgDmEzlmlTV13Pb35aTER/H7ycO9jiPSYppT6GlATqPnuQ3L9jOzE4Cezrl3D/eFzGyamWWaWWZ+fv4RhxU5Gg+/u4YtBeX8+dJRusa5BLVj3ilqZh2Ax4E7mlrXOTfDOZfhnMtISdH1pqXlLVy9m1mLtjPtx/04pX+y13FEWlRzCn0H0LPR8/SGZd+JB4YDn5rZVmA8MF87RsVre0qquOftFQxPS+COs3XhLQl+zSn0xcAAM+trZpHAFGD+dy8654qdc8nOuT7OuT7AN8Ak51xmiyQWaQa/33HnW1lU1tbx1JTRRIbrCF0Jfk3+lDvnfMDNwEJgLTDHObfazB4ys0ktHVDkaMz4YjNfbCzgwfOHcVxKnNdxRFpFs27N4pxbACw4YNmDh1j39GOPJXL0lm3fx58XrufcEd2ZOrZn058gEiT0d6gElZKqWn49exndEqL540UjMdPZoBI6dPNECRrOOe5/ZxU7i6qYM/0kEmN0iKKEFo3QJWjMXpzDv7J28puzBjKmdyev44i0OhW6BIU1O0v47fzV/HhAMr887Tiv44h4QoUu7V5pVS03zVpKp9gInrz8eF1FUUKW5tClXXPOcc+8lWwvrODNG8fTJS7K60gintEIXdq1177exrsrdnHH2QMZ27ez13FEPKVCl3ZrybZCHv73Gs4c3JVfnKp5cxEVurRL+aXV/OqNpaQmxfC45s1FAM2hSzvkq/Nzy5tLKaqoZd6vTtTx5iINVOjS7jzy3jq+2VzIny8dxbDURK/jiLQZmnKRdmXe0lxe/J8t/Pyk3lwyJt3rOCJtigpd2o0VuUXcM28l4/t15oHzf3BbW5GQp0KXdiG/tJrpM5eQEhfFM1ecQESYfnRFDqQ5dGnzqmrrmDYzk30VNcz9xck6eUjkEFTo0qY557h77gqWbS/iuStPYHiadoKKHIr+bpU27amPNzI/ayd3TxzExOE9vI4j0qap0KXN+ufyHTz50UYuPiFdV1AUaQYVurRJX20q4M63shjbtzN/uGi47jwk0gwqdGlz1u0uYfprS+jTpSMvXJVBVHiY15FE2gUVurQpu4orufblxcREhvHKdWNJjNVp/SLNpaNcpM3YV17D1S99S2mVj79PH09aUozXkUTaFRW6tAll1T6ueWUx2woreOXaE3WNFpGjoCkX8Vy1r47pMzNZtaOYp6eO5uTjkr2OJNIuqdDFU7V1fm6ZtYwvs/fy2MUjOXtYd68jibRbKnTxjK/Oz62zl/HBmj38btIwLtbVE0WOiQpdPOGr83P7nCwWrNzNA+cN4ecn9/E6kki716xCN7OJZrbezLLN7J6DvP4bM1tjZivM7GMz6x34qBIsfHV+7ngri39l7eSecwZzw4/7eR1JJCg0WehmFgY8A5wDDAWmmtmBF6NeBmQ450YCc4HHAh1UgkONz88tby7jn8t3ctdPB/ELndIvEjDNGaGPBbKdc5udczXAbGBy4xWcc5845yoann4DaDJUfqCqto5fvr6E91bVT7Pc9JP+XkcSCSrNKfQ0IKfR89yGZYdyPfDewV4ws2lmlmlmmfn5+c1PKe1eWbWP619dzMfr8vj9hcM1zSLSAgJ6YpGZXQlkAKcd7HXn3AxgBkBGRoYL5HtL21VQVs21Ly9mza4S/nLpKB3NItJCmlPoO4CejZ6nNyz7HjObANwPnOacqw5MPGnvcgoruOqlRewuqeKFq8dwxuBuXkcSCVrNKfTFwAAz60t9kU8Brmi8gpmNBp4HJjrn8gKeUtql5TlF3PBqJj6/nzduGM+Y3p28jiQS1JqcQ3fO+YCbgYXAWmCOc261mT1kZpMaVvsTEAe8ZWbLzWx+iyWWduHdFbu4/PmviY0MY+4vTlKZi7SCZs2hO+cWAAsOWPZgo48nBDiXtFPOOf770038aeF6xvTuxIyrxuimziKtRFdblIApr/Zx99wVvLtyF5NGpfLYJSOJjtDNKURaiwpdAmJrQTnTZmaSnVfGvecMZtqp/XTbOJFWpkKXY/b+ql3cNXcFYR2M164bx48G6PK3Il5QoctRq6qt448L1vLq19sYlZ7I01ecQM/OsV7HEglZKnQ5Khv3lHLr7OWs2VXCDT/qy90TBxMZrot3inhJhS5HxO93vPzVVh59fx1xUeG8eHUGE4bqZCGRtkCFLs2WU1jBf7y9gq827WXCkK788aKRpMTrkESRtkKFLk2q8zte/nILf/lgAx0MHrloBJef2FNHsYi0MSp0OayVucU88I+VZOUWc8bgrvz+wuGkJsV4HUtEDkKFLgdVVFHDnxauZ9a32+nSMZK/Th3NBSN7aFQu0oap0OV7anx+Zi3axlMfb6Skysc1J/fh9rMGkhAd4XU0EWmCCl2A+muwvL9qN4++v46teys4qV8XfjtpKIO7J3gdTUSaSYUe4pxzfLohnyc+3MCK3GIGdI3j5WtO5PRBKZpeEWlnVOgh6rsi/78fb2Tp9iLSO8Xw2MUjueiENMLDdIKQSHukQg8xvjo/767cxbOfbmLd7lJSE6P5w89GcMmYdJ3pKdLOqdBDxL7yGmYvzmHm11vZWVxF/65x/PnSUUwalaoiFwkSKvQg5pxj6fYiZn+7nX+t2ElVrZ+Tj+vC7yYP58zBXenQQXPkIsFEhR6E8kqrmL98J29l5rJ+TymxkWH8bHQ615zch0Hd472OJyItRIUeJEqravl4bR7/WL6DLzYWUOd3jEpP5I8XjeCCUanERelbLRLs9Fveju0rr+GT9XksWLmbzzfmU+Pzk5oYzS9O68fPRqfRv6tG4yKhRIXejjjnWL+nlM/W5/Pxujwytxbid9A9IZorx/XmvJHdGd2zk+bGRUKUCr2N21Vcydeb9vLVpr18sTGfPSXVAAzuHs9NP+nPhCHdGJGWqBIXERV6W+L3OzYXlJG5dR+Lt+4jc1sh2/ZWAJAUG8EpxyVz6sBkTh2YQo9EXfFQRL5Phe4R5xzbCytYvbOEVTuKycotYkVOMaXVPgA6d4xkTO9OXDW+Nycd14Uh3RM0CheRw1KhtzDnHAVlNWTnlZGdV8q63aWsb3h8V97hHYzBPeKZdHwqo3omMaZ3J/old9S1VETkiKjQA8A5x97yGnIKK9heWMG2vRVsLShny95ythSUU1RRu3/d+OhwBnePZ/LoVIalJjI8NZEB3eKIjgjzcAtEJBio0Jvg9zv2VdSwp6SavNIq9pRUsau4it3FVewsrmLHvgp2FlVRWVv3vc9LTYymT3JHzh3Rg/4pcfTvWv/okRitkbeItIiQKnS/31Fe46O4srb+UVFLUWUt+ypqKKqoZW9ZDYXl1ewtr2FvWQ0FZdUUltfg87vvfR0zSI6LokdiNAO7xXP6oK6kJcXQu0ssvTrHkt4plphIjbhFpHU1q9DNbCLwFBAGvOice+SA16OA14AxwF7gcufc1sBGrZdTWMHGvFIqauqoqKmjcv+/Pspr6iiv9lFW7dv/b2lV/b8llbWUVfs4oJu/JzYyjM4dI+nSMZIeidGMSEskOT6SlLgouiZE0y0hiq7x0XRLiNYFrUSkzWmy0M0sDHgGOAvIBRab2Xzn3JpGq10P7HPO9TezKcCjwOUtEfjdlbt45L11B8kJsRFhdIwKJy4qnNioMOKjIujZOZb4qHASYiKIjw4nPjqcpJhIEmIiSIyJICk2gk6xkSTFRmgeW0TateaM0McC2c65zQBmNhuYDDQu9MnAfzV8PBd42szMOXeY8fDRufD4NE7q14WYyDBiIsKIiQyjY2Q40REdNDctIiGtOYWeBuQ0ep4LjDvUOs45n5kVA12AgsYrmdk0YBpAr169jipw98RouidGH9XniogEs1adCHbOzXDOZTjnMlJSUlrzrUVEgl5zCn0H0LPR8/SGZQddx8zCgUTqd46KiEgraU6hLwYGmFlfM4sEpgDzD1hnPvDzho8vAf5fS8yfi4jIoTU5h94wJ34zsJD6wxb/5pxbbWYPAZnOufnAS8BMM8sGCqkvfRERaUXNOg7dObcAWHDAsgcbfVwFXBrYaCIiciR0doyISJBQoYuIBAkVuohIkFChi4gECRW6iEiQUKGLiAQJFbqISJBQoYuIBAkVuohIkFChi4gECRW6iEiQUKGLiAQJ8+oqt2aWD2zz5M2PTTIH3IkpRITidmubQ0d72u7ezrmD3iHIs0Jvr8ws0zmX4XWO1haK261tDh3Bst2achERCRIqdBGRIKFCP3IzvA7gkVDcbm1z6AiK7dYcuohIkNAIXUQkSKjQRUSChAr9GJjZHWbmzCzZ6ywtzcz+ZGbrzGyFmb1jZkleZ2pJZjbRzNabWbaZ3eN1npZmZj3N7BMzW2Nmq83sVq8ztRYzCzOzZWb2b6+zHCsV+lEys57A2cB2r7O0kg+B4c65kcAG4F6P87QYMwsDngHOAYYCU81sqLepWpwPuMM5NxQYD9wUAtv8nVuBtV6HCAQV+tF7ArgbCIm9ys65D5xzvoan3wDpXuZpYWOBbOfcZudcDTAbmOxxphblnNvlnFva8HEp9QWX5m2qlmdm6cB5wIteZwkEFfpRMLPJwA7nXJbXWTxyHfCe1yFaUBqQ0+h5LiFQbt8xsz7AaGCRt0laxZPUD8z8XgcJhHCvA7RVZvYR0P0gL90P3Ef9dEtQOdw2O+f+2bDO/dT/ef5Ga2aT1mFmccDbwG3OuRKv87QkMzsfyHPOLTGz073OEwgq9ENwzk042HIzGwH0BbLMDOqnHpaa2Vjn3O5WjBhwh9rm75jZNcD5wJkuuE9g2AH0bPQ8vWFZUDOzCOrL/A3n3Dyv87SCU4BJZnYuEA0kmNnrzrkrPc511HRi0TEys61AhnOuvVyp7aiY2UTgceA051y+13lakpmFU7/j90zqi3wxcIVzbrWnwVqQ1Y9OXgUKnXO3eZ2ntTWM0O90zp3vdZZjoTl0aa6ngXjgQzNbbmbPeR2opTTs/L0ZWEj9zsE5wVzmDU4BrgLOaPj+Lm8YuUo7ohG6iEiQ0AhdRCRIqNBFRIKECl1EJEio0EVEgoQKXUQkSKjQRUSChApdRCRI/H8eMNJfMLbRAgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"hfiu_eRtKq2d"},"source":["<h3>Why do we need to use a \"Non-linear\" activation function?</h3>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","According to the textbook, it seems that an activation function transforms the input value and transmits the transformed one to another layer. Thus, the output layer receives the value of a composite function composed of the activation function of each layer. \n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","However, composition of linear functions is always linear. For example, let $f(x)=ax+b$, then $$f(f(x))=a(ax+b)+b=a^2x+b(1+a)$$, which is linear as well. This implies that if a linear function is used as an activation function, the given neural network is equivalent to a single-layer network regardless of how many layers the given one has.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Now, let's try to learn and implement another activation function. This function is called 'ReLU', which stands for \"Rectified Linear Unit\". Formula of this function looks like:\n","$$h(x)=\n","  \\begin{cases} \n","  x & x > 0 \\\\\n","  0 & x\\leq 0 \n","  \\end{cases}\n","$$\n","And this can also be expressed as: $$\\max(x,0)$$\n","Now, let's implement the ReLU function with <code>Python</code>.\n","</p>"]},{"cell_type":"code","metadata":{"id":"8RZP_wcoIhmI","executionInfo":{"status":"ok","timestamp":1633064845152,"user_tz":-540,"elapsed":72,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["relu = lambda x: np.maximum(x, 0)\n","\n","# works exactly the same as def relu(x): return np.maximum(x,0)\n","\n","# warning: np.max(a, b) != np.maximum(a, b)\n","# np.max: returns the most largest one among the entire variables, column by column.\n","# np.maximum: returns larger number between two."],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phhgEt_rYmGm","executionInfo":{"status":"ok","timestamp":1633064845152,"user_tz":-540,"elapsed":70,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"99c74e16-a5c6-485f-e3b1-bdbadb5760bd"},"source":["# put scalar into the relu function\n","print(relu(-2))\n","print(relu(10))\n","\n","# put vector into the relu function\n","A = np.array([[1, 2], [-2, 10]], dtype=np.float64)\n","print(relu(A))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10\n","[[ 1.  2.]\n"," [ 0. 10.]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"F-CEWgqqZkhJ"},"source":["# Multi-dimension Vector Computation"]},{"cell_type":"markdown","metadata":{"id":"ig6xJxtNapfH"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","In linear algebra, the word \"dimension\" refers to, informally, the minimum number of coordinates needed to specify any points within it. For example, a scalar corresponds to one point on the number line, thus only one coordinate, say $x$, is needed to specify the scalar, therefore a scalar is one-dimensional.<br>\n","Or, simply put, a dimension can be regarded as the cardinality of a vector, i.e. the number of elements in the vector. \n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Let's think about the coordinate plane. As you might know, the coordinate plane always consists of two axes: $x$ and $y$. Also, any points within the plane is expressed as a tuple, composed of one scalar from the $x$-axis and the other from the $y$-axis. Thus, we call that the coordinate plane has two dimensions.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","However, in <code>Numpy</code>, a dimension indicates the number of numbers explaining the shape of a vector. For example, let <code>A = np.array([[1, 2], [3, 4]])</code> be a numpy array. Mathematically, this array is equivalent to a matrix:\n","$$ A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} $$\n","And we call this matrix a $2 \\times 2$ matrix composed of two rows and two columns. Also, this matrix is two-dimensional, since each (column) vector composing it is two-dimensional.<br>\n","Likewise, if you try to retrieve the shape of that Numpy array, the value <code>(2, 2)</code> will be returned.\n","</p>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTWm7FYoY2Qz","executionInfo":{"status":"ok","timestamp":1633064845153,"user_tz":-540,"elapsed":66,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"a595eab4-1721-4eb6-fa94-f1e1b93d0ae2"},"source":["A = np.array([[1, 2], [3, 4]], dtype=np.float64)\n","print(np.shape(A))\n","print(A.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 2)\n","(2, 2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eLHq_FmkCP_","executionInfo":{"status":"ok","timestamp":1633064845153,"user_tz":-540,"elapsed":62,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"19bc8972-7b99-425f-a1d3-3add3782d0a5"},"source":["A"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 2.],\n","       [3., 4.]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"WttgSpWwgZrU"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","Although we call the given array <code>A</code> to be two-dimensioanal as well, the reason is not the same as why we call the given matrix $A$ is two-dimensional.<br>\n","<strong>The array <code>A</code> is two-dimensional because the shape consists two numbers.</strong>\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Simply put, the dimension of a Numpy array can be understood as the number of brackets in the array, unit by unit. There is a small bracket surrounding two elements inside, and a big bracket surroungding two small brackets inside. Therefore, the given array has two dimensions.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","As a further example, let's think about a Numpy array <code>B = np.array([[[1, 2], [2, 1]], [[4, 5], [6, 7]]])</code>.<br>\n","What is the dimension of the array <code>B</code>? The answer is 3, since it is composed of three brackets. Specifically, each of the innermost bracket has two elements(numbers) inside, and each two of those innermost brackets are surrounded by a middle-size bracket. Finally, there is the outermost bracket around those two middle-size brackets.<br>\n","Furthermore, the exact shape of the array is (2, 2, 2).\n","</p>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpKt_ZSOgVF4","executionInfo":{"status":"ok","timestamp":1633064845154,"user_tz":-540,"elapsed":59,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"3ab302e8-2f64-4ea8-c939-b368fcb02581"},"source":["B = np.array([[[1, 2], [2, 1]], [[4, 5], [6, 7]]], dtype=np.float64)\n","print(np.shape(B))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 2, 2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYBlCFoYkDyG","executionInfo":{"status":"ok","timestamp":1633064845154,"user_tz":-540,"elapsed":55,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"1c494e46-14da-44b5-aaaf-6fda6a83b502"},"source":["B"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[1., 2.],\n","        [2., 1.]],\n","\n","       [[4., 5.],\n","        [6., 7.]]])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5KMiPR1jlj5","executionInfo":{"status":"ok","timestamp":1633064845155,"user_tz":-540,"elapsed":53,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"ccb9e3e9-abfa-4ccf-b405-3de89faaeb45"},"source":["np.ndim(B)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"-wV0Uyoyj3ee"},"source":["## Matrix Multiplication"]},{"cell_type":"markdown","metadata":{"id":"IQw2rxjSkIN4"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","The most important thing to be noticed for matrix multiplication is that the shape of two (or more) matrices should match each other.\n","</p>"]},{"cell_type":"code","metadata":{"id":"pVbsdJUtl0CR","executionInfo":{"status":"ok","timestamp":1633064845155,"user_tz":-540,"elapsed":51,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def mat_mul(A, B):\n","  try:\n","    X = np.matmul(A, B)\n","    print(X)\n","    print(\"The shape of the result array is: {}\".format(np.shape(X)))\n","  except Exception as e:\n","    print(e)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0dJrCPYkHp1","executionInfo":{"status":"ok","timestamp":1633064845156,"user_tz":-540,"elapsed":52,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"7a0396d5-d40f-4679-dd85-bfc14f168f5e"},"source":["# does not return error, since the shape of arrays inside the outermost bracket of B matches that of A.\n","# and both the dimension and the shape of the result follows those of the array with bigger ones.\n","\n","print(\"Shape of each matrix is : {0} and {1}\".format(np.shape(A), np.shape(B)))\n","print(mat_mul(A, B)) # A is 2-dimensional, B is 3-dimenstional\n","print(\"================\")\n","print(mat_mul(B, A))"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of each matrix is : (2, 2) and (2, 2, 2)\n","[[[ 5.  4.]\n","  [11. 10.]]\n","\n"," [[16. 19.]\n","  [36. 43.]]]\n","The shape of the result array is: (2, 2, 2)\n","None\n","================\n","[[[ 7. 10.]\n","  [ 5.  8.]]\n","\n"," [[19. 28.]\n","  [27. 40.]]]\n","The shape of the result array is: (2, 2, 2)\n","None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inYYmKERj1iq","executionInfo":{"status":"ok","timestamp":1633064845156,"user_tz":-540,"elapsed":49,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"e6510d73-d7fa-4f03-f61a-23b1c4da373a"},"source":["# does not return error either\n","C = np.array([[[-1, 0], [0, -1]]], dtype=np.float64)\n","\n","print(\"Shape of each matrix is : {0} and {1}\".format(np.shape(A), np.shape(C)))\n","print(mat_mul(A, C))\n","print(\"================\")\n","print(mat_mul(C, A))"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of each matrix is : (2, 2) and (1, 2, 2)\n","[[[-1. -2.]\n","  [-3. -4.]]]\n","The shape of the result array is: (1, 2, 2)\n","None\n","================\n","[[[-1. -2.]\n","  [-3. -4.]]]\n","The shape of the result array is: (1, 2, 2)\n","None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTItP35plrrW","executionInfo":{"status":"ok","timestamp":1633064845157,"user_tz":-540,"elapsed":47,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"a9b9c531-5627-44d2-c51c-fb64e06d62ec"},"source":["# returns errors\n","D = np.array([[[-1], [0]], [[-1], [0]]], dtype=np.float64)\n","\n","print(\"Shape of each matrix is : {0} and {1}\".format(np.shape(A), np.shape(D)))\n","print(mat_mul(A, D))\n","print(\"================\")\n","print(mat_mul(D, A)) # since (2, 1) cannot be multiplicated with (2, 2)"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of each matrix is : (2, 2) and (2, 2, 1)\n","[[[-1.]\n","  [-3.]]\n","\n"," [[-1.]\n","  [-3.]]]\n","The shape of the result array is: (2, 2, 1)\n","None\n","================\n","matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 1)\n","None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SmxU6DqenHC_","executionInfo":{"status":"ok","timestamp":1633064845158,"user_tz":-540,"elapsed":45,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"6200b5ea-46fc-48ac-c868-b706a30773a3"},"source":["E = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n","              [[9, 8, 7], [6, 5, 4], [3, 2, 1]],\n","              [[-1, 0, 1], [0, 2, 1], [-2, 3, 1]]], dtype=np.float64)\n","F = np.array([[[1, 0, 1],\n","               [0, 1, 0],\n","               [1, 1, 1]]], dtype=np.float64)\n","\n","print(\"Shape of each matrix is : {0} and {1}\".format(np.shape(E), np.shape(F)))\n","print(mat_mul(E, F))\n","print(\"================\")\n","print(mat_mul(F, E)) # since (2, 1) cannot be multiplicated with (2, 2)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of each matrix is : (3, 3, 3) and (1, 3, 3)\n","[[[ 4.  5.  4.]\n","  [10. 11. 10.]\n","  [16. 17. 16.]]\n","\n"," [[16. 15. 16.]\n","  [10.  9. 10.]\n","  [ 4.  3.  4.]]\n","\n"," [[ 0.  1.  0.]\n","  [ 1.  3.  1.]\n","  [-1.  4. -1.]]]\n","The shape of the result array is: (3, 3, 3)\n","None\n","================\n","[[[ 8. 10. 12.]\n","  [ 4.  5.  6.]\n","  [12. 15. 18.]]\n","\n"," [[12. 10.  8.]\n","  [ 6.  5.  4.]\n","  [18. 15. 12.]]\n","\n"," [[-3.  3.  2.]\n","  [ 0.  2.  1.]\n","  [-3.  5.  3.]]]\n","The shape of the result array is: (3, 3, 3)\n","None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y0756-voo3LJ","executionInfo":{"status":"ok","timestamp":1633064845158,"user_tz":-540,"elapsed":42,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"d52fc68d-1774-4ce0-94f7-d3993ddabc2f"},"source":["# np.dot or matrix.dot works exactly the same as the np.matmul\n","import math\n","\n","A = np.array([[math.pi, math.exp(1)], [-2, -5]], dtype=np.float64)\n","B = np.array([[np.sin(3), np.cos(-1)], [np.sqrt(3), 0.7]], dtype=np.float64)\n","\n","X = np.matmul(A, B)\n","Y = np.dot(A, B)\n","Z = A.dot(B)\n","print(X)\n","print(Y)\n","print(Z)\n","print(X == Y)\n","print(Y == Z)\n","print(Z == X)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 5.15154382  3.60020703]\n"," [-8.94249405 -4.58060461]]\n","[[ 5.15154382  3.60020703]\n"," [-8.94249405 -4.58060461]]\n","[[ 5.15154382  3.60020703]\n"," [-8.94249405 -4.58060461]]\n","[[ True  True]\n"," [ True  True]]\n","[[ True  True]\n"," [ True  True]]\n","[[ True  True]\n"," [ True  True]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"3MhPZpWZqki8"},"source":["### Implementation of neural network using matrix multiplication"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DinAgULrqHXj","executionInfo":{"status":"ok","timestamp":1633064845159,"user_tz":-540,"elapsed":40,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"67a442f4-680b-45f7-f6ec-dc62c7522fff"},"source":["X = np.array([1, 2])\n","print(np.shape(X))\n","\n","W = np.array([[1, 3, 5],\n","              [2, 4, 6]], dtype=np.float64)\n","print(W)\n","print(np.shape(W))\n","\n","Y = np.matmul(X, W)\n","print(Y)\n","print(Y.shape)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["(2,)\n","[[1. 3. 5.]\n"," [2. 4. 6.]]\n","(2, 3)\n","[ 5. 11. 17.]\n","(3,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ykFThrO-rM2a"},"source":["# Implementation of Multi-layer neural network (Feedforward)"]},{"cell_type":"markdown","metadata":{"id":"V-qOOkexshWE"},"source":["## Some notations"]},{"cell_type":"markdown","metadata":{"id":"7SOaZ1KasjqI"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","<ol style=\"font-size:13pt;line-height:19pt\">\n","<li>Input vector is denoted as $X$, and $x_i$ denotes the $i$-th element of the vector.</li>\n","<li>Intermediate vector, i.e. a vector of $j$-th hidden layer is denoted as $A^{(j)}$, and thus $a^{(j)}_i$ denotes the $i$-th element of the $j$-th layer.</li>\n","<li>Weight matrix of the $j$-th layer, which is multiplied by the input vector if $j=1$ and is multipled by the intermediate vector otherwise, is denoted as $W^{(j)}$.</li>\n","<ul style=\"font-size:11pt;line-height:19pt\">\n","<li>Each weight in weight, is denoted as $w^{(j)}_{ik}$, where $j$ denotes the current layer, $i$ denotes the $i$-th element of the next layer, and $k$ denotes the $k$-th element of the current layer.</li>\n","</ul>\n","<li>$b^{(j)}_{i}$ denotes the $i$-th bias of the $j$-th layer.</li>\n","<li>Finally, the output vector is denoted as $Y$, and $y_i$ denotes the $i$-th element of the output layer.</li>\n","</ol>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"zf7bjTOdvy1E"},"source":["## Feedforward propagation"]},{"cell_type":"markdown","metadata":{"id":"hJZN6hfxv4Cw"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","Each element of the hidden layer is calculated as the linear combination between the elements in the previous layer and the weight.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","For example, think about a 3-layer neural network, where input vector $X \\in \\mathbb{R}^{2} $ the 1<sup>st</sup> element of the first hidden layer, $a^{(1)}_{1}$ is calculated as:\n","$$ a^{(1)}_{1} = w^{(1)}_{11}x_1 + w^{(1)}_{12}x_2 + b_1^{(1)}$$\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","The matrix expression would be like:\n","$$ \\begin{pmatrix} a^{(1)}_{1} \\\\ a^{(1)}_{2} \\end{pmatrix} = \\begin{pmatrix} w^{(1)}_{11}x_1 + w^{(1)}_{12}x_2 + b_1^{(1)} \\\\ w^{(1)}_{21}x_1 + w^{(1)}_{22}x_2 + b_2^{(1)} \\end{pmatrix} $$\n","which is equivalent to:\n","$$ \\begin{pmatrix} a^{(1)}_{1} \\\\ a^{(1)}_{2} \\end{pmatrix} = \\begin{pmatrix} x_1 & x_2 \\end{pmatrix} \\begin{pmatrix} w^{(1)}_{11} & w^{(1)}_{21} \\\\ w^{(1)}_{12} & w^{(1)}_{22} \\end{pmatrix}  + \\begin{pmatrix} b_1^{(1)} \\\\ b_2^{(1)} \\end{pmatrix} $$\n","Thus,\n","$$ A^{(1)} = X^{T}W^{(1)} + b^{(1)}$$\n","Note: The number of rows of the weight matrix denotes the number of nodes in the current layer, and the number of columns denots the number of nodes in the next layer.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Implementation is like below.\n","</p>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6E5Rz_2q-qs","executionInfo":{"status":"ok","timestamp":1633064845159,"user_tz":-540,"elapsed":37,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"beebe27c-47ef-48e6-c6e7-04c68432688b"},"source":["X = np.array([1, 0.5], dtype=np.float64)\n","W1 = np.array([[0.1, 0.3, 0.5],\n","              [0.2, 0.4, 0.6]], dtype=np.float64)\n","B1 = np.array([0.1, 0.2, 0.3], dtype=np.float64)\n","\n","print(np.shape(X), np.shape(W1), np.shape(B1))"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["(2,) (2, 3) (3,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8MZcfFh1J75","executionInfo":{"status":"ok","timestamp":1633064845160,"user_tz":-540,"elapsed":35,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"c80dc46f-684d-4f1f-f6f8-bbb426dfc94e"},"source":["A1 = np.matmul(X, W1) + B1\n","print(np.shape(A1))\n","A1"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["(3,)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0.3, 0.7, 1.1])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ra5Fbzp51anl","executionInfo":{"status":"ok","timestamp":1633064845161,"user_tz":-540,"elapsed":33,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"8ecfd29e-2041-4cee-c52f-eb513b0da1e4"},"source":["A1_t = np.matmul(np.transpose(W1), X) + B1\n","print(np.shape(A1_t))\n","A1_t"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["(3,)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0.3, 0.7, 1.1])"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"kqHVMR2D1v9J"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","Also, an activation is applied on transmission from each layer to another.\n","</p>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5_eYNs81gB3","executionInfo":{"status":"ok","timestamp":1633064845161,"user_tz":-540,"elapsed":30,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"3081aa77-7ce8-4a7f-8c01-ffc433aba22e"},"source":["# if an activation is a sigmoid function\n","Z1_sig = sigmoid(A1)\n","\n","# if an activation is a ReLU function\n","Z1_relu = relu(A1)\n","\n","print(Z1_sig)\n","print(Z1_relu)"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.57444252 0.66818777 0.75026011]\n","[0.3 0.7 1.1]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ficbTebj2dWA","executionInfo":{"status":"ok","timestamp":1633064845162,"user_tz":-540,"elapsed":28,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"38c17a38-b11c-42b5-fe8e-e49985ec3ec0"},"source":["# 2nd layer\n","W2 = np.array([[0.1, 0.4],\n","               [0.2, 0.5],\n","               [0.3, 0.6]], dtype=np.float64) # 3 by 2 matrix, since 3 elements in the 1st layer and 2 elements in 2nd.\n","B2 = np.array([0.1, 0.2], dtype=np.float64)\n","\n","A2_sig = np.dot(Z1_sig, W2) + B2\n","A2_relu = np.dot(Z1_relu, W2) + B2\n","\n","print(A2_sig)\n","print(A2_relu)\n","\n","Z2_sig = sigmoid(A2_sig)\n","Z2_relu = relu(A2_relu)\n","print(Z2_sig)\n","print(Z2_relu)\n","\n","Z2_sr = sigmoid(A2_relu)\n","Z2_rs = relu(A2_sig)\n","print(Z2_sr)\n","print(Z2_rs)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.51615984 1.21402696]\n","[0.6  1.33]\n","[0.62624937 0.7710107 ]\n","[0.6  1.33]\n","[0.64565631 0.79084063]\n","[0.51615984 1.21402696]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAQo0PfP4Smv","executionInfo":{"status":"ok","timestamp":1633064845162,"user_tz":-540,"elapsed":26,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"f7ec6ada-dcb7-422e-efa2-8343c0d5ba10"},"source":["# 3rd layer to output\n","W3 = np.array([[0.1, 0.3],\n","               [0.2, 0.4]], dtype=np.float64) # 2 by 2 matrix, since 2 elements in the 2nd layer and 2 elements in the output layer.\n","B3 = np.array([0.1, 0.2], dtype=np.float64)\n","\n","A3_sr = np.dot(Z2_sr, W3) + B3\n","A3_rs = np.dot(Z2_rs, W3) + B3\n","\n","print(A3_sr)\n","print(A3_rs)\n","\n","# just return the same value as the output\n","def identity(X): return X\n","\n","y_sr = identity(A3_sr)\n","y_rs = identity(A3_rs)\n","\n","print(y_sr)\n","print(y_rs)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.32273376 0.71003315]\n","[0.39442138 0.84045873]\n","[0.32273376 0.71003315]\n","[0.39442138 0.84045873]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bt5g3zrn6g3N","executionInfo":{"status":"ok","timestamp":1633064845545,"user_tz":-540,"elapsed":406,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"409043f5-38b2-4e9a-bbb4-005d6b7dc800"},"source":["# Aggregation\n","def init_network():\n","  network = dict()\n","  network['W1'] = np.array([[0.1, 0.3, 0.5], \n","                            [0.2, 0.4, 0.6]], dtype=np.float64)\n","  network['b1'] = np.array([0.1, 0.2, 0.3], dtype=np.float64)\n","  network['W2'] = np.array([[0.1, 0.4],\n","                            [0.2, 0.5],\n","                            [0.3, 0.6]], dtype=np.float64)\n","  network['b2'] = np.array([0.1, 0.2], dtype=np.float64)\n","  network['W3'] = np.array([[0.1, 0.3],\n","                            [0.2, 0.4]], dtype=np.float64)\n","  network['b3'] = np.array([0.1, 0.2], dtype=np.float64)\n","\n","  return network\n","\n","def forward(X, network):\n","  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","\n","  a1 = np.matmul(X, W1) + b1\n","  z1 = sigmoid(a1)\n","  a2 = np.matmul(z1, W2) + b2\n","  z2 = relu(a2)\n","  a3 = np.matmul(z2, W3) + b3\n","  y = identity(a3)\n","\n","  return y\n","\n","network = init_network()\n","X = np.array([1, 0.5])\n","y = forward(X, network)\n","y"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.39442138, 0.84045873])"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"J7znryKrFOsY"},"source":["# Output layer"]},{"cell_type":"markdown","metadata":{"id":"88lllFmtFYvX"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","Although we used the identity function as an activation function from the final hidden layer to the output layer, which activation function to use depends on the purpose of learning: regression or classification.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Generally, for regression, the identity function is used, while the Softmax function is used for classification.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","The identity function is very simple: $y_k=a_k$, and the Softmax function also has a somewhat simple form:\n","$$ y_k=\\frac{\\exp(a_k)}{\\sum_{i=1}^{n}\\exp(a_i)}$$\n","This functional form implies that every node of the final hidden layer is used - as a denominator - to compute the $k$-th node of the output layer, while for the identity function, each node of the final hidden layer equals to the corresponding node of the output layer.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","However, the exponential function value increases much more rapidly than an input value increases, implying that it can cause 'stack overflow'. To prevent this problem, the Softmax function is transformed like below.\n","$$ \\frac{\\exp(a_k)}{\\sum_{i=1}^{n}\\exp(a_i)}=\\frac{C\\exp(a_k)}{C\\sum_{i=1}^{n}\\exp(a_i)} \\\\ \n","= \\frac{\\exp(\\log C)\\exp(a_k)}{\\exp(\\log C)\\sum_{i=1}^{n}\\exp(a_i)} \\\\\n","= \\frac{\\exp(a_k+\\log C)}{\\sum_{i=1}^{n}\\exp(a_i + \\log C)} \\\\ $$\n","Where $ C'=\\log C $ is constant. This implies that even if we add a constant to the formula, the result is not influenced. Therefore, to address the stack overflow problem, the maximum element of a given vector is subtracted from each element. This can be implemented as below. \n","</p>"]},{"cell_type":"code","metadata":{"id":"iI8lkXrH5sib","executionInfo":{"status":"ok","timestamp":1633064845545,"user_tz":-540,"elapsed":8,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def softmax(X):\n","  # X: np.array equivalent to a vector\n","  c = np.max(X)\n","  exp_X = np.exp(X - c)\n","  sum_exp = np.sum(exp_X)\n","  y = exp_X / sum_exp\n","\n","  return y"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deeBkokZMcSz","executionInfo":{"status":"ok","timestamp":1633064845546,"user_tz":-540,"elapsed":8,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"9381337d-dea2-4e70-8113-3c88c41c7192"},"source":["a = np.array([1010, 1000, 990],dtype=np.float64)\n","\n","softmax(a)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"Jorp9n66h0uT"},"source":["## Interpretation of Softmax function"]},{"cell_type":"markdown","metadata":{"id":"jWak7MtZh4gy"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","The output vector returned from the softmax function has several features.\n","<ol style=\"font-size:13pt;line-height:19pt\">\n","<li>Sum of all elements is always equal to 1. This implies that the $i$-th element represents the probability such that the given input belongs to the $i$-th class.</li>\n","<li>As $\\exp(x)$ is an increasing function, the order relation between variables remains the same.</li>\n","<li>Typically, the Softmax function is only used for training, not testing or inference.</li>\n","</ol>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"_GCvxsRaMZpc"},"source":["## How to determine the number of output nodes"]},{"cell_type":"markdown","metadata":{"id":"cUr3HWKpNRWu"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","The number of the output nodes depends on what kind of problem you want to solve.\n","<ul style=\"font-size:13pt;line-height:19pt\">\n","<li>For classification, the number of output nodes is equal to that of the classes.</li>\n","<li>While for regression, there is no rules (or even rules of thumb) to determine the number of output nodes.</li>\n","</ul>\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"2cHMAb4_QCDA"},"source":["# Example - Mnist Handwritten Digit Recognition"]},{"cell_type":"markdown","metadata":{"id":"-o6Ba44BQP2p"},"source":["## 1. Data Import"]},{"cell_type":"code","metadata":{"id":"y9gzfDrMMlsK","executionInfo":{"status":"ok","timestamp":1633065621288,"user_tz":-540,"elapsed":378,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["# import dataset from scikit-learn\n","from sklearn.datasets import fetch_openml"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UWeZ5oOCSTal","executionInfo":{"status":"ok","timestamp":1633065664711,"user_tz":-540,"elapsed":24909,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"ee801327-de02-45ad-d212-eb1f3de93550"},"source":["mnist = fetch_openml('mnist_784', version=1)\n","mnist.keys()"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"6QJXUk8_TB2E","executionInfo":{"status":"ok","timestamp":1633065776593,"user_tz":-540,"elapsed":379,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["x, y = mnist['data'], mnist['target']\n","\n","# split the data into the training set and the test set\n","x_train, x_test = x[:60000], x[60000:]\n","y_train, y_test = y[:60000], y[60000:]"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eij5H9LDTjJo","executionInfo":{"status":"ok","timestamp":1633065804791,"user_tz":-540,"elapsed":374,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"b6325e22-ef70-47a5-d65b-adb27b86ac46"},"source":["print(np.shape(x_train))\n","print(np.shape(y_train))\n","print(np.shape(x_test))\n","print(np.shape(y_test))"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 784)\n","(60000,)\n","(10000, 784)\n","(10000,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"E3Kl2rYIUx6l"},"source":["## 2. EDA - load image"]},{"cell_type":"markdown","metadata":{"id":"PDxz_69VU182"},"source":["### 2-1. Using PIL"]},{"cell_type":"code","metadata":{"id":"0Ni2MDJ1TqCG","executionInfo":{"status":"ok","timestamp":1633066151629,"user_tz":-540,"elapsed":387,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["from PIL import Image"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"3EIAQ9YEU-sI","executionInfo":{"status":"ok","timestamp":1633066404624,"user_tz":-540,"elapsed":369,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def img_show(img):\n","  pil_img = Image.fromarray(np.uint8(img))\n","  pil_img.show()"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PP5InYL4VFUh","executionInfo":{"status":"ok","timestamp":1633066349041,"user_tz":-540,"elapsed":381,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"9613bafe-8c47-49c1-fd13-0a693720fce2"},"source":["img = x_train[0]\n","label = y_train[0]\n","print(label)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7fIItmTVu3o","executionInfo":{"status":"ok","timestamp":1633066370494,"user_tz":-540,"elapsed":377,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"8db27683-b957-4e9d-e41d-b7ec9cf7117e"},"source":["print(np.shape(img))"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["(784,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7THEkioV0JS","executionInfo":{"status":"ok","timestamp":1633066390464,"user_tz":-540,"elapsed":437,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"2ac9a188-3375-4282-c947-e44741f6d54e"},"source":["img = np.reshape(img, (28, 28))\n","np.shape(img)"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"xc7CwbUxV5Ae","executionInfo":{"status":"ok","timestamp":1633066406566,"user_tz":-540,"elapsed":363,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["img_show(img)"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iTbApkhWWA6y"},"source":["### 2-2. MatPlotLib"]},{"cell_type":"code","metadata":{"id":"Igf57vjSV6T3","executionInfo":{"status":"ok","timestamp":1633066498366,"user_tz":-540,"elapsed":403,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"jq0UYkmVWRaK","executionInfo":{"status":"ok","timestamp":1633066556124,"user_tz":-540,"elapsed":384,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"ab0754eb-779a-4a94-ea59-ee3079913900"},"source":["plt.imshow(img, cmap='binary')\n","plt.axis('off')\n","plt.show()"],"execution_count":58,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"8rQ8GP--WmyS"},"source":["## 3. Building a Neural Network"]},{"cell_type":"markdown","metadata":{"id":"b6Z0YpRpXQjQ"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","We are going to re-use the functions we defined above for prediction.\n","</p>"]},{"cell_type":"code","metadata":{"id":"B2tVWXChdNGV","executionInfo":{"status":"ok","timestamp":1633069715769,"user_tz":-540,"elapsed":378,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["import pickle\n","from datetime import datetime"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"FflqQemtZtuw","executionInfo":{"status":"ok","timestamp":1633068314504,"user_tz":-540,"elapsed":384,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def init_network():\n","  with open('/content/drive/MyDrive//deep-learning-from-scratch/ch03/sample_weight.pkl', 'rb') as f:\n","    network = pickle.load(f)\n","  \n","  return network"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yZYXz8bWhTU","executionInfo":{"status":"ok","timestamp":1633068315413,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}}},"source":["def predict(X, network):\n","  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n","  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n","\n","  a1 = np.matmul(X, W1) + b1\n","  z1 = sigmoid(a1)\n","  a2 = np.matmul(z1, W2) + b2\n","  z2 = relu(a2) # used ReLU instead of the Sigmoid\n","  a3 = np.matmul(z2, W3) + b3\n","  y = softmax(a3)\n","\n","  return y"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRmJ8fu-XsyN","executionInfo":{"status":"ok","timestamp":1633069771514,"user_tz":-540,"elapsed":11778,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"d8479355-f758-4376-eae3-b95c35260d13"},"source":["network = init_network()\n","\n","start = datetime.now()\n","\n","accuracy_cnt = 0 # Metric for model evaluation\n","for i in range(len(x_train)):\n","  if i % 10000 == 0:\n","    print(i)\n","  y = predict(x_train[i], network) # returns 10 values, each representing the probability of the given input belonging to the class\n","  p = np.argmax(y) # returns the argument such that has the maximum value among y\n","  if np.float(p) == np.float(y_train[i]): # if the argmax equals to the true value\n","    accuracy_cnt += 1\n","\n","end = datetime.now()\n","\n","print(\"training_time: {}\".format(end - start))"],"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n","  \n"]},{"output_type":"stream","name":"stdout","text":["10000\n","20000\n","30000\n","40000\n","50000\n","training_time: 0:00:11.249923\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI-nZ6ELdF_C","executionInfo":{"status":"ok","timestamp":1633069776798,"user_tz":-540,"elapsed":380,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"8e093d0c-a348-47ae-ff8b-487daf3d2132"},"source":["# print(accuracy_cnt)\n","accuracy = str(float(accuracy_cnt) / len(x_train))\n","print('Accuracy: {}'.format(accuracy))"],"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["54329\n","Accuracy: 0.9054833333333333\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pn2LjO-XfRWV"},"source":["## 4. Batch Training"]},{"cell_type":"markdown","metadata":{"id":"2jeZRcnAfoyg"},"source":["<p style=\"font-size:13pt;line-height:19pt\">\n","The word 'Batch' means \"a group that is dealt with at the same time.\" From the perspective of data analysis, batch can be viewed as 'a small set of training set that are trained at the same time.'\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","The batch training has a very strong advantage: it reduces the training time. Since a computer is optimized to compute a big and sparse dataset efficiently, batch training takes much less time than training one element by one element.\n","</p>\n","<p style=\"font-size:13pt;line-height:19pt\">\n","Let $n$ be the batch size and $k$ be the number of classes. If we train the dataset one by one, the shape of the output is ($k$,), which is a $k$-dimensional vector. However, if we train the dataset by batch, the shape of output is ($n$,$k$), which is a $n\\times k$ matrix. \n","</p>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IChdRdSoeR4J","executionInfo":{"status":"ok","timestamp":1633069906874,"user_tz":-540,"elapsed":1030,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"5b7219c1-ba9a-4eb1-c895-dd4ab113b952"},"source":["# implementation of batch training\n","network = init_network()\n","batch_size = 200\n","\n","start = datetime.now()\n","\n","accuracy_cnt = 0 # Metric for model evaluation\n","for i in range(0, len(x_train), batch_size): # increment i by the amount of batch_size\n","  if i % 10000 == 0:\n","    print(i)\n","  x_batch = x_train[i:i+batch_size]\n","  y_batch = predict(x_batch, network) # returns a 100*10 matrix\n","  p = np.argmax(y_batch, axis=1) # returns a vector, containing the maximum value of each column\n","  \n","  p = np.array(p, dtype=np.float64)\n","  truevals = np.array(y_train[i:i+batch_size], dtype=np.float64)\n","\n","  accuracy_cnt += np.sum(p == truevals) # returns how many predicted values are equal to the corresponding true values\n","\n","end = datetime.now()\n","\n","print(\"training_time: {}\".format(end - start))"],"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10000\n","20000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n","  \n"]},{"output_type":"stream","name":"stdout","text":["30000\n","40000\n","50000\n","training_time: 0:00:00.489295\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOjuCafxifEx","executionInfo":{"status":"ok","timestamp":1633069910689,"user_tz":-540,"elapsed":386,"user":{"displayName":"Sungwoo Coding","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17899964297313081808"}},"outputId":"34ed6fd8-c405-4a1c-cdec-553dfe00e58d"},"source":["# print(accuracy_cnt)\n","accuracy = str(float(accuracy_cnt) / len(x_train))\n","print('Accuracy: {}'.format(accuracy))"],"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9054833333333333\n"]}]},{"cell_type":"code","metadata":{"id":"COq84OI9i-Gb"},"source":[""],"execution_count":null,"outputs":[]}]}